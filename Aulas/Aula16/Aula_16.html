<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Aula 16 - Modelos de Espaço de Estados</title>
    <meta charset="utf-8" />
    <meta name="author" content="Renato Rodrigues Silva" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Aula 16 - Modelos de Espaço de Estados
## Material baseado no livro de Morettin e Toloi (2004)
### Renato Rodrigues Silva
### Universidade Federal de Goiás.
### (updated: 2020-08-14)

---

class: middle
##Introdução (Glaura Franco e Dani Gammerman)

- A metodologia de *modelos estruturais*, ou *modelos dinâmicos*, é uma das várias abordagens existentes para a modelagem de séries temporais. 

- A premissa básica destes modelos consiste em admitir a existência de componentes não
observáveis de tendência, sazonalidade, ciclo e ruído aleatório.

- A ideia dessa decomposição da série temporal surgiu nos trabalhos de Holt (1957) e Winters (1960) que desenvolveram as tecnicas de alisamento exponencial.

- Os primeiros modelos estruturais surgiram na década de 60 com os trabalhos de  Muth (1960), Theil &amp; Wage (1964) e Nervole &amp; Wage (1964). 

- No entanto, mediante a dificuldade computacional da época e do aparecimento da metodologia Box &amp; Jenkins (1976), a ideia de decomposição em componentes não observáveis só voltaram a ser desenvolvidas no final da década de 80.

---
class: middle
##Introdução (Glaura Franco  e Dani Gammerman)

- A principal vantagem dos modelos é que ao invés de ajustar funções que descrevem os componentes não observáveis aos dados históricos, estes procedimentos procuram identificar os componentes básicos na série e o modelo resultante é obtido a partir da composição desses elementos.

- Ou seja, este tipo de modelo supõe que os movimentos característicos de uma série temporal `\(\left\{ Z_t \right\}, t = 1,...n\)`, podem ser decompostos em componentes não-observáveis, como por exemplo, tendência, sazonalidade, componente cíclica e componente aleatória ou erro. 

- **Esses modelos estruturais são então escritos na forma de espaço de estados** e permitem a utilização do filtro de Kalman (1960).

---
class: middle
##Alguns modelos específicos

---
class: middle
##Modelo de Nível Local (MNL)

- É o modelo estrutural mais simples e é adequado quando o nível da série muda 
com o tempo de acordo com um passeio aleatório, isto é

`\begin{align}
Z_t =&amp; \mu_t + \epsilon_t, \phantom{111} t = 1, \ldots, N, \\
\mu_t =&amp; \mu_{t-1} + \eta_t, \phantom{111} t = 1, \ldots, N.
\end{align}`
em que `\(\epsilon \sim N(0,\sigma_{\epsilon}^2)\)`, `\(\eta_t \sim N(0, \sigma^2_{\eta})\)` independentes e não correlacionadas entre si.


---
class: middle
##Modelo de tendência local

- Esse modelo é descrito pelas seguintes equações:

`\begin{align}
Z_t   =&amp; \mu_t + \epsilon_t \\
\mu_t =&amp; \mu_{t-1} + \beta_{t-1} + \eta_t \\
\beta_t =&amp; \beta_{t-1} + \xi_t.
\end{align}`
em que `\(\epsilon_t \sim N(0,\sigma^2_{\epsilon})\)`, 
`\(\eta_t \sim N(0,\sigma^2_{\eta})\)` e `\(\xi_t \sim N(0,\sigma^2_{\xi})\)`
com `\(\eta_t\)` e `\(\xi_t\)` mutuamente não 
correlacionados e não correlacionados com `\(\epsilon_t\)`, `\(\mu_t\)` é denominado
nível local e `\(\beta_t\)` a inclinação local.

---
class: middle
##Modelo de tendência local - Casos Particulares

1.  Nível local ou passeio aleatório + ruído; neste caso `\(\beta_t = 0\)`.

2.  Nível local com "drift"; neste caso `\(\sigma_{\xi}^2 = 0\)`.

3.  Tendência suave; neste caso `\(\sigma_{\eta}^2 = 0\)`.

4.  Tendência determinística; neste caso `\(\sigma_{\eta}^2 = \sigma_{\xi}^2 = 0\)`.

####Obs:

- A especificação da tendência é baseada em informações a priori da série e/ou no gráfico das observações.

- Na dúvida estima-se o modelo geral e testa-se a significância de cada componente no vetor de estados. Em particular, se `\(\sigma_{\xi}^2 = 0\)`, podemos testar se `\(\beta\)`, agora fixo, também é zero.



---
class: middle
##Modelo Estrutural Básico

- O modelo estrutural básico é definido por meio de:

`\begin{align}
Z_t   =&amp; \mu_t + \gamma_t + \epsilon_t \\
\mu_t =&amp; \mu_{t-1} + \beta_{t-1} + \eta_t \\
\beta_t =&amp; \beta_{t-1} + \xi_t. \\
\gamma_t =&amp; - S_{t-1} - \ldots - S_{t-s+1} + \omega_t
\end{align}`
assumindo que `\(t = 1, \ldots, n\)` e que `\(s\)` refere-se ao número de períodos 
sazonais, `\(\epsilon_t \sim N(0,\sigma^2_{\epsilon})\)`, 
`\(\eta_t \sim N(0,\sigma^2_{\eta})\)`, `\(\xi_t \sim N(0,\sigma^2_{\xi})\)` e
`\(\omega_t \sim N(0,\sigma_{\omega}^2)\)`, 

- com `\(\epsilon_t\)`, `\(\omega_t\)`, `\(\eta_t\)` e `\(\xi_t\)` são ruídos brancos mutuamemte não 
correlacionados.


---
class: inverse, middle, center
##Representação em espaço de estados


---
class: middle
##Representação em espaço de estados

- Todo modelo linear de séries temporais `\(q\)`-dimensionais tem representação em espaço de estados.

- Essa representação relaciona o vetor de observações `\(\left\{ Z_t \right\}\)` e o vetor de ruídos `\(\nu_t\)`, através de um processo de Markov `\(\left\{ X_t \right\}\)`, `\(p\)` dimensional, denominado vetor de estados.

- O modelo de espaço de estados é constituídos por duas equações: a equação de observação e a equação de estados.


---
class: middle
##Representação em espaço de estados

- Matematicamente, o modelo de espaço de estados para uma série temporal univariada pode ser representado da seguinte maneira:

`\begin{align}
Z_t   =&amp; \mathbf{A}_t \mathbf{X}_t + \nu_t \phantom{111} \mbox{(equação de observação)}\\
\mathbf{X}_{t}  =&amp; \mathbf{G}_t \mathbf{X}_{t-1}  + \mathbf{w}_t, \phantom{11} t = 1, \ldots, N.  \phantom{111} \mbox{(equação de estado)}
\end{align}`

em que `\(\mathbf{A}\)` é a matriz do sistema (matriz de variáveis explanatórias), de ordem `\((q \times p)\)`;

- `\(\nu_t\)` é o ruído de observação, de ordem `\((q \times 1)\)`, não correlacionado, com média zero e variância `\(\mathbf{R}\)`;

- `\(\mathbf{G}\)` é a matriz de transição (matriz de evolução), de ordem  `\((p \times p)\)` e 

- `\(\mathbf{w}_t\)` é um vetor de ruídos não correlacionados, representando a perturbação do sistema, de ordem `\((p \times 1)\)`, com média zero e matriz de covariâncias `\(\textbf{Q}\)`.

- Para séries univariadas tem-se `\(q=1\)`.

---
class: middle
##Representação em espaço de estados

- No modelo de espaço de estados assume-se que:

- O estado inicial `\(\mathbf{X}_0\)` tem média `\(\boldsymbol{\mu}_0\)` e matriz de covariâncias `\(\boldsymbol{\Sigma}_0\)`;

- os vetores de ruídos `\(\nu_t\)` e `\(\mathbf{w}_t\)` são não correlacionados entre si e não correlacionados com o estado inicial, isto é,

- `\(E[\nu_t\mathbf{w}_s^{'}] = 0, \phantom{11} \forall t, s = 1, \ldots, N.\)`
- `\(E[\nu_t\mathbf{X}_0^{'}] = 0 \phantom{11} \mbox{e} \phantom{11} E[\mathbf{w}_t\mathbf{X}_0^{'}] = 0, \phantom{11} \forall t, s = 1, \ldots, N.\)`

- Dizemos que o modelo de espaço de estados é gaussiano quando vetores de ruídos forem normalmente distribuídos. 

- O vetor `\(\mathbf{A}\)` e a matriz `\(\mathbf{G}\)` são não estocásticas; assim se houver variação no tempo estes serão pré-determinados. Quando forem constantes no tempo será dito *homogêneo no tempo*.

- O vetor de estados **não é diretamente observado**; o que se observa é uma versão linear dele, adicionada a um ruído. 



---
class: inverse, middle, center
##Inferência Sequencial

---
class: middle
##Inferência Sequencial (Hedibert Freitas Lopes)

- Um dos aspectos de um modelo dinâmico é que em qualquer tempo `\(t\)`, a inferência pode ser baseada na distribuição atualizada `\(\mathbf{X}_t|\mathbf{Z}_t\)`.

- Inferência sequencial executa isso ao longo do tempo:

- Existem 3 operações básicas:

- Evolução;

- Predição;

- Atualização.

---
class: middle
##Evolução (Hedibert Freitas Lopes)

- Evolução de `\(p(\mathbf{X}_{t-1}|\mathbf{Z}^{t-1})\)` para `\(p(\mathbf{X}_t|\mathbf{Z}^{t-1})\)`.

- Considere no instante `\(t-1\)`, a distribuição atualizada de `\(\mathbf{X}_{t-1}\)` condicionada a `\(\mathbf{Z}^{t-1}\)` como sendo

`$$\mathbf{X}_{t-1}|\mathbf{Z}^{t-1} \sim N(\mathbf{x}_{t-1}^{t-1}, \mathbf{P}^{t-1}_{t-1}).$$`

em que `\(\mathbf{Z}^{t-1} = \left[Z_1, Z_2, \ldots, Z_{t-1}\right],\)` `\(\mathbf{x}_{t-1}^{t-1} = E[\mathbf{X}_{t-1}|\mathbf{Z}^{t-1}]\)` e
`\(\mathbf{P}^{t-1}_{t-1} = Var[\mathbf{X}_{t-1}|\mathbf{Z}^{t-1}].\)`

- Supondo que os ruídos e os estados sejam normalmente distribuídos, a partir da equação do sistema podemos determinar a distribuição `\(\mathbf{X}_t\)` condicionado a `\(\mathbf{X}_{t-1}\)`, ou seja,

`$$\mathbf{X}_t|\mathbf{X}_{t-1} \sim N(\mathbf{G}_t\mathbf{X}_{t-1}, \mathbf{Q}).$$`

---
class: middle
##Evolução (Hedibert Freitas Lopes)

- Agora supondo propriedade Markoviana temos:

`$$p(\mathbf{X}_{t-1}, \mathbf{X}_{t}|\mathbf{Z}^{t-1}) = p(\mathbf{X}_{t-1}|\mathbf{Z}^{t-1}) p(\mathbf{X}_t|\mathbf{X}_{t-1}).$$`

Consequentemente, a distribuição de `\(\mathbf{X}_{t}\)` condicionado a `\(\mathbf{Z}^{t-1}\)` é dada por:


`$$p(\mathbf{X}_t|\mathbf{Z}^{t-1}) = \int p(\mathbf{X}_{t-1}, \mathbf{X}_{t}|\mathbf{Z}^{t-1}) d \mathbf{X}_{t-1}$$`
em que utilizando propriedades de [esperança condicional](https://en.wikipedia.org/wiki/Conditional_expectation#Basic_properties) e de [variância condicional](https://en.wikipedia.org/wiki/Law_of_total_variance) temos:

`\begin{align}
E[\mathbf{X}_t|\mathbf{Z}^{t-1}] =&amp; E[E[\mathbf{X}_t|\mathbf{X}_{t-1}]|\mathbf{Z}^{t-1}] \\
=&amp; E[\mathbf{G}_t  \mathbf{X}_{t-1} | \mathbf{Z}^{t-1} ] = \mathbf{G}_t 
E[\mathbf{X}_{t-1} | \mathbf{Z}^{t-1} ] = \mathbf{G}_t \mathbf{x}_{t-1}^{t-1}.
\end{align}`

`\begin{align}
Var[\mathbf{X}_t|\mathbf{Z}^{t-1}] =&amp; E[Var[\mathbf{X}_t|\mathbf{X}_{t-1}, \mathbf{Z}^{t-1}]|\mathbf{Z}^{t-1}] +
Var[E[\mathbf{X}_{t} | \mathbf{X}_{t-1},\mathbf{Z}^{t-1} ]|\mathbf{Z}^{t-1}]  \\
=&amp; E[Var[\mathbf{X}_t|\mathbf{X}_{t-1}]|\mathbf{Z}^{t-1}] +
Var[E[\mathbf{X}_{t} | \mathbf{X}_{t-1} ]|\mathbf{Z}^{t-1}] \\
=&amp; \mathbf{Q} + Var[\mathbf{G}_{t}  \mathbf{X}_{t-1} |\mathbf{Z}^{t-1}] \\
=&amp;  \mathbf{Q} + \mathbf{G}_{t}\mathbf{P}_{t-1}^{t-1} \mathbf{G}_{t}^{'}.
\end{align}`

Logo, `\(\mathbf{X}_t|\mathbf{Z}^{t-1} \sim N(\mathbf{G}_t \mathbf{x}_{t-1}^{t-1}, \mathbf{Q} + \mathbf{G}_{t}\mathbf{P}_{t-1}^{t-1} \mathbf{G}_{t}^{'} ).\)`

---
class: middle
##Predição (Hedibert Freitas Lopes)

- Uma predição a um passo a frente pode ser feita, notando que

`\begin{align}
p(Z_t, \mathbf{X}_t|\mathbf{Z}^{t-1}) = p(\mathbf{X}_t|\mathbf{Z}^{t-1}) p(Z_t|\mathbf{X}_t) 
\end{align}`
pois estamos assumindo que `\(Z_t|\mathbf{X}_t \perp \mathbf{Z}^{t-1}.\)`

- Assim, a distribuição de `\(Z_t, \mathbf{X}_t| \mathbf{Z}^{t-1}\)` pode ser obtida levando a seguinte distribuição:

`$$p(Z_t | \mathbf{Z}^{t-1}) = \int p(Z_t, \mathbf{X}_t| \mathbf{Z}^{t-1}) d\mathbf{X}_t$$`

Ou seja, `\(\mathbf{Z}_t | \mathbf{Z}_{t-1} \sim N(\mathbf{A}_t\mathbf{x}_{t}^{t-1}, \mathbf{A}_t\mathbf{P}_t^{t-1}\mathbf{A}_t^{'}+\mathbf{R}),\)` pois a partir da equação de observação


`\begin{align}
E[Z_t|\mathbf{Z}^{t-1}] =&amp; E[E[Z_t|\mathbf{X}_{t}]|\mathbf{Z}^{t-1}] \\
=&amp; E[\mathbf{A}_t  \mathbf{X}_{t} | \mathbf{Z}^{t-1} ] = \mathbf{A}_t 
E[\mathbf{X}_{t} | \mathbf{Z}^{t-1} ] = \mathbf{A}_t \mathbf{x}_{t}^{t-1}.
\end{align}`

`\begin{align}
Var[Z_t|\mathbf{Z}^{t-1}] =&amp; E[Var[Z_t|\mathbf{X}_{t}, \mathbf{Z}^{t-1}]|\mathbf{Z}^{t-1}] +
Var[E[Z_{t} | \mathbf{X}_{t},\mathbf{Z}^{t-1} ]|\mathbf{Z}^{t-1}]  \\
=&amp; E[Var[Z_t|\mathbf{X}_{t}]|\mathbf{Z}^{t-1}] +
Var[E[Z_{t} | \mathbf{X}_{t} ]|\mathbf{Z}^{t-1}] \\
=&amp; \mathbf{R} + Var[\mathbf{A}_{t}  \mathbf{X}_{t} |\mathbf{Z}^{t-1}] \\
=&amp;  \mathbf{R} + \mathbf{A}_{t}\mathbf{P}_{t}^{t-1} \mathbf{A}_{t}^{'}.
\end{align}`


---
class: middle
##Atualização  - Filtro de Kalman (Hedibert Freitas Lopes)

- A atualização é desenvolvida via Teorema de Bayes

`$$p(\mathbf{X}_t|\mathbf{Z}^t) = p(\mathbf{X}_t|Z_t,\mathbf{Z}^{t-1}) = \frac{p(Z_t|\mathbf{X}_t,\mathbf{Z}^{t-1})p(\mathbf{X}_t|\mathbf{Z}^{t-1})}{p(Z_t|\mathbf{Z}^{t-1})} = \frac{p(Z_t|\mathbf{X}_t)p(\mathbf{X}_t|\mathbf{Z}^{t-1}) }{p(Z_t|\mathbf{Z}^{t-1})}.$$`
- Portanto, a distribuição conjunta é dada por 
`$$p(Z_t|\mathbf{X}_t,\mathbf{Z}^{t-1})p(\mathbf{X}_t|\mathbf{Z}^{t-1}) = p(\mathbf{X}_t, Z_t|\mathbf{Z}^{t-1}),$$`

- Ou seja,

`\begin{eqnarray}
\left[
\begin{array}{c}
\mathbf{X}_t | \mathbf{Z}_{t-1}\\
Z_{t} | \mathbf{Z}_{t-1}  
\end{array} \right]
\sim 
N \left(
  \left[
    \begin{array}{c}
    \mathbf{x}_t^{t-1} \\
    \mathbf{A} \mathbf{x}_t^{t-1}
    \end{array} \right], 
  \left[
    \begin{array}{cc}
    \mathbf{P}_t^{t-1} &amp; \mathbf{P}_t^{t-1}\mathbf{A}^{'} \\
      \mathbf{A}\mathbf{P}_t^{t-1} &amp; \mathbf{A}\mathbf{P}_t^{t-1}\mathbf{A}^{'} + \mathbf{R}
    \end{array} \right] \right).
\end{eqnarray}`


- Aplicando [propriedades de normal multivariada](https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Conditional_distributions), temos: `\(\mathbf{X}_t|\mathbf{Z}^t \sim N(\mathbf{x}_{t}^{t},\mathbf{P}_{t}^{t}),\)` em que

`$$\mathbf{x}_{t}^{t} =  \mathbf{x}_{t}^{t-1} + \mathbf{P}_{t}^{t-1}\mathbf{A}^{'}(\mathbf{A}\mathbf{P}_{t}^{t-1}\mathbf{A}^{'} + \mathbf{R})^{-1}(Z_t - \mathbf{A}\mathbf{x}_{t}^{t-1})$$`
e variância

`\begin{align}
\mathbf{P}_{t}^{t} = \mathbf{P}_{t}^{t-1} - \mathbf{P}_{t}^{t-1}\mathbf{A}^{'}(\mathbf{A}\mathbf{P}_{t}^{t-1}\mathbf{A}^{'} + \mathbf{R})^{-1}\mathbf{A}\mathbf{P}_{t}^{t-1}) 
= \left[\mathbf{I} - \mathbf{P}_{t}^{t-1}\mathbf{A}^{'} (\mathbf{A}\mathbf{P}_{t}^{t-1}\mathbf{A}^{'} + \mathbf{R})^{-1}\mathbf{A}\right]\mathbf{P}_{t}^{t-1}.
\end{align}`


---
class: middle
##Suavizador de Kalman - Algoritmo

- Para os modelos dinâmicos com condições iniciais `\(\mathbf{x}_N^N\)` e `\(\mathbf{P}_N^N,\)` temos para `\(t = N, N-1, \ldots, 1.\)`

`\begin{align}
\mathbf{x}_{t-1}^N =&amp; \mathbf{x}_{t-1}^{t-1} + \mathbf{J}_{t-1}(\mathbf{x}_{t}^N -\mathbf{x}_{t}^{t-1} ) \\
\mathbf{P}_{t-1}^N =&amp; \mathbf{P}_{t-1}^{t-1} +  \mathbf{J}_{t-1}(\mathbf{P}_{t}^N - \mathbf{P}_{t}^{t-1})\mathbf{J}_{t-1}^{'}
\end{align}`

em que `\(\mathbf{J}_{t-1} =  \mathbf{P}_{t-1}^{t-1}\mathbf{G}_t\left[\mathbf{P}_{t}^{t-1}\right]^{-1}.\)`

- Assim, o suavizador de Kalman fornece as estimativas do vetor de estados e da matriz de covariâncias no instante `\(t-1\)`, utilizando como informação todas as observações `\(Z_1, Z_2, \ldots, Z_N\)` da série temporal. [explicações](https://communities.sas.com/t5/SAS-Communities-Library/Kalman-Filtering-and-Kalman-Smoothing-in-PROC-UCM/ta-p/338797#:~:text=Kalman%20filtering%20uses%20all%20the,and%20uses%20all%20the%20data.&amp;text=The%20smoothing%20gives%20a%20good,matrix%20of%20the%20state%20variables.) [ou](https://christophertonetti.com/files/notes/Nakata_Tonetti_KalmanFilterAndSmoother.pdf.) 


---
class: middle
##Função de Verossimilhança

- A função de verossimilhança pode ser calculada através das quantidades obtidas pelo filtro de Kalman.

- Suponha `\(Z_t | \mathbf{Z}_{t-1} \sim N(\mathbf{A}\mathbf{x}_{t}^{t-1},\mathbf{A}\mathbf{P}_{t}^{t-1}\mathbf{A}^{'} + \mathbf{R})\)` e considere agora `\(\epsilon_t = Z_t - E[Z_t|\mathbf{Z}_{t-1}]\)`. Dessa forma, temos:

`\begin{align}
  E[\epsilon_t] =&amp; E[Z_t - E[Z_t|\mathbf{Z}_{t-1}]] \\
  =&amp; E[Z_t] - E[E[Z_t|\mathbf{Z}_{t-1}]] \\
  =&amp; E[Z_t] - E[Z_t] \\
  =&amp; 0.
\end{align}`

`\begin{align}
  Var[\epsilon_t] =&amp; Var[Z_t - E[Z_t|\mathbf{Z}^{t-1}]] \\
  =&amp; Var[Z_t - E[Z_t|\mathbf{Z}^{t-1}]] \\
  =&amp; Var[\mathbf{A}\mathbf{X}_{t} + \nu_t - \mathbf{A}\mathbf{x}_{t}^{t-1}] \\
  =&amp; Var[\mathbf{A}(\mathbf{X}_{t} - \mathbf{x}_{t}^{t-1})] + Var[\nu_t ] \\
  =&amp; \mathbf{A}Var[(\mathbf{X}_{t} - \mathbf{x}_{t}^{t-1})]\mathbf{A}^{'} + \mathbf{R} 
\end{align}`

---
class: middle
##Função de Verossimilhança

- Lembrando que 

`\begin{align}
Var[(\mathbf{X}_{t} - \mathbf{x}_{t}^{t-1})] =&amp; E[(\mathbf{X}_t - \mathbf{x}_{t}^{t-1})(\mathbf{X}_t - \mathbf{x}_{t}^{t-1})^{'} ] \\
=&amp;  E[(\mathbf{X}_t - \mathbf{x}_{t}^{t-1})(\mathbf{X}_t - \mathbf{x}_{t}^{t-1})^{'}|\mathbf{Z}^{t-1} ] = \mathbf{P}_{t}^{t-1}
\end{align}`

Logo,

`\begin{align}
 \boldsymbol{\Sigma}_{\epsilon_t} = Var[\epsilon_t] = \mathbf{A}\mathbf{P}_{t}^{t-1}\mathbf{A}^{'} + \mathbf{R}. 
\end{align}`


Assim, podemos definir o logaritmo da função de verossimilhança da seguinte forma

`$$l(\Theta|\mathbf{Z}) = -\frac{1}{2}\sum_{t=1}^N\log|\boldsymbol{\Sigma}_{\epsilon_t}| - \frac{1}{2}\sum_{t=1}^N \boldsymbol{\epsilon}_t^{'}\boldsymbol{\Sigma}_{\epsilon_t}^{-1}\boldsymbol{\epsilon}_t,$$`

- Nesse caso, o logaritmo da função de verossmilhança é não linear com relação aos parâmetros, então métodos numéricos devem ser adotados.


---
class: inverse, middle, center
##Exemplos Práticos no R


---
class: middle
##Exemplos 1 - Série `\(A_{10}\)`

- Como primeiro exemplo vamos analisar a Série `\(A_{10}\)`: Índice de Custo de Vida no Município de São Paulo; observações mensais de janeiro de 1970 a junho de 1980.

- O primeiro passo seria plotar a série para verificar qual modelo estrutural é o mais adequado.

---
class: middle
##Exemplos 1 - Série `\(A_{10}\)`


![](Aula_16_files/figure-html/unnamed-chunk-1-1.png)&lt;!-- --&gt;

---
class: middle
##Exemplos 1 - Série `\(A_{10}\)`

- Analisando os gráficos dos slides anteriores, decidiu-se utilizar o modelo estrutural de tendência local para os dados em escala logaritmica.

####Modelo Estrutural

`\begin{align}
Z_t   =&amp; \mu_t + \epsilon_t \\
\mu_t =&amp; \mu_{t-1} + \beta_{t-1} + \eta_t \\
\beta_t =&amp; \beta_{t-1} + \xi_t.
\end{align}`

####Modelo Estrutural na Forma de Espaço de Estados

`\begin{eqnarray}
Z_t =&amp; 
\left[
\begin{array}{cc}
1 &amp; 0
\end{array} \right]
\left[
\begin{array}{c}
\mu_t \\
\beta_t
\end{array} \right] + \epsilon_t \\
\left[
\begin{array}{c}
\mu_t \\
\beta_t
\end{array} \right] =&amp;
\left[
\begin{array}{cc}
1 &amp; 1 \\
0 &amp; 1
\end{array} \right]
\left[
\begin{array}{c}
\mu_{t-1} \\
\beta_{t-1}
\end{array} \right] +
\left[
\begin{array}{c}
\eta_{t} \\
\xi_{t-1}
\end{array} \right]
\end{eqnarray}`





---
class: middle
##Código em R 


```r
dados = ts(log(dat$ICV), start=c(1970,1), frequency=12)

#Ajuste de um modelo com tendência local  
mod &lt;- StructTS(dados, type = "trend")
if (mod$code != 0) stop("optimizer did not converge")

cat("Transitional variance:", mod$coef["level"],
"\n", "Slope variance:", mod$coef["slope"],
"\n", "Observational variance:", mod$coef["epsilon"],
"\n")
```


---
class: middle

####Estimativas dos Parâmetros de Variâncias

```
## Transitional variance: 0.0001054708 
##  Slope variance: 8.153826e-06 
##  Observational variance: 0
```



###Valores preditos dos estados latentes (Filtro de Kalman)


```
##   Obs Pred.level Pred.slope
## 1 120   6.955593 0.05124951
## 2 121   6.999422 0.04945347
## 3 122   7.032624 0.04551952
## 4 123   7.074963 0.04474962
## 5 124   7.120444 0.04492670
## 6 125   7.177019 0.04774619
## 7 126   7.225481 0.04791963
```

####Código para Diagnostico do Modelo


```r
tsdiag(mod)
```

---
class: middle

##Diagnostico do Modelo

![](Aula_16_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;



---
class:  middle

##Suavização - Código em R

![](Aula_16_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;
                                         

---
class:  middle

##Suavização - Código em R


```r
pred = tsSmooth(mod)
plot(pred)
```
  
##Previsão 12 meses na frente


```r
KalmanForecast(mod$model,n.ahead=12)
```

---
class:  middle

##Suavização - Código em R

![](Aula_16_files/figure-html/unnamed-chunk-11-1.png)&lt;!-- --&gt;

---
class:  middle



```
## $pred
##  [1] 7.273401 7.321321 7.369240 7.417160 7.465080 7.512999 7.560919 7.608839
##  [9] 7.656758 7.704678 7.752597 7.800517
## 
## $var
##  [1] 0.0001391554 0.0003538336 0.0006603425 0.0010749895 0.0016140824
##  [6] 0.0022939289 0.0031308365 0.0041411130 0.0053410659 0.0067470030
## [11] 0.0083752318 0.0102420601
```

---
class: middle

##Interpretação dos Resultados 


- Analises dos resultados sugerem que o ruído da observação seja nulo, pois, `\(\sigma^2_{\epsilon} = 0.\)` (Conclusão tirada do livro do Morettin).

- Uma vez que a variância da inclinação também é um valor baixo, vamos testar o modelo de passeio aleatório.


---
class: middle
####Exemplos 1 - Passeio Aleatório

`\begin{align}
Z_t   =&amp; \mu_t \\
\mu_t =&amp; \mu_{t-1} +  \eta_t.
\end{align}`

####Modelo Estrutural na Forma de Espaço de Estados

Reconhecendo que `\(\mathbf{A}_t = 1, \mathbf{X_t} = \mu_t, \nu_t = 0, \mathbf{G}_t = 1, w_t = \eta_t\)`, tem-se o modelo de passeio aleatório representado como um modelo de espaço de estados.



---
class: middle
####Passeio Aleatório - Código no R


```r
mod2 = StructTS(dados, type = "level", fixed = c(NA,0))

cat("Transitional variance:", mod2$coef["level"],"\n")
```

```
## Transitional variance: 0.0007669502
```



---
class: middle

##Diagnostico do Modelo

![](Aula_16_files/figure-html/unnamed-chunk-14-1.png)&lt;!-- --&gt;

---
class: middle

####Interpretação dos Resultados 

 - Entre esses dois modelos ficamos com o primeiro, pois análise de diagnostico do passeio aleatório indica que o modelo está mal especificado.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
