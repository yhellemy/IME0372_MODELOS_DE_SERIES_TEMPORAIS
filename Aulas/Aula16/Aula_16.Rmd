---
title: "Aula 16 - Modelos de Espaço de Estados"
subtitle: "Material baseado no livro de Morettin e Toloi (2004)"
author: "Renato Rodrigues Silva"
institute: "Universidade Federal de Goiás."
date: "(updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false

    
---
class: middle
##Introdução (Glaura Franco e Dani Gammerman)

- A metodologia de *modelos estruturais*, ou *modelos dinâmicos*, é uma das várias abordagens existentes para a modelagem de séries temporais. 

- A premissa básica destes modelos consiste em admitir a existência de componentes não
observáveis de tendência, sazonalidade, ciclo e ruído aleatório.

- A ideia dessa decomposição da série temporal surgiu nos trabalhos de Holt (1957) e Winters (1960) que desenvolveram as tecnicas de alisamento exponencial.

- Os primeiros modelos estruturais surgiram na década de 60 com os trabalhos de  Muth (1960), Theil & Wage (1964) e Nervole & Wage (1964). 

- No entanto, mediante a dificuldade computacional da época e do aparecimento da metodologia Box & Jenkins (1976), a ideia de decomposição em componentes não observáveis só voltaram a ser desenvolvidas no final da década de 80.

---
class: middle
##Introdução (Glaura Franco  e Dani Gammerman)

- A principal vantagem dos modelos é que ao invés de ajustar funções que descrevem os componentes não observáveis aos dados históricos, estes procedimentos procuram identificar os componentes básicos na série e o modelo resultante é obtido a partir da composição desses elementos.

- Ou seja, este tipo de modelo supõe que os movimentos característicos de uma série temporal $\left\{ Z_t \right\}, t = 1,...n$, podem ser decompostos em componentes não-observáveis, como por exemplo, tendência, sazonalidade, componente cíclica e componente aleatória ou erro. 

- **Esses modelos estruturais são então escritos na forma de espaço de estados** e permitem a utilização do filtro de Kalman (1960).

---
class: middle
##Alguns modelos específicos

---
class: middle
##Modelo de Nível Local (MNL)

- É o modelo estrutural mais simples e é adequado quando o nível da série muda 
com o tempo de acordo com um passeio aleatório, isto é

\begin{align}
Z_t =& \mu_t + \epsilon_t, \phantom{111} t = 1, \ldots, N, \\
\mu_t =& \mu_{t-1} + \eta_t, \phantom{111} t = 1, \ldots, N.
\end{align}
em que $\epsilon \sim N(0,\sigma_{\epsilon}^2)$, $\eta_t \sim N(0, \sigma^2_{\eta})$ independentes e não correlacionadas entre si.


---
class: middle
##Modelo de tendência local

- Esse modelo é descrito pelas seguintes equações:

\begin{align}
Z_t   =& \mu_t + \epsilon_t \\
\mu_t =& \mu_{t-1} + \beta_{t-1} + \eta_t \\
\beta_t =& \beta_{t-1} + \xi_t.
\end{align}
em que $\epsilon_t \sim N(0,\sigma^2_{\epsilon})$, 
$\eta_t \sim N(0,\sigma^2_{\eta})$ e $\xi_t \sim N(0,\sigma^2_{\xi})$
com $\eta_t$ e $\xi_t$ mutuamente não 
correlacionados e não correlacionados com $\epsilon_t$, $\mu_t$ é denominado
nível local e $\beta_t$ a inclinação local.

---
class: middle
##Modelo de tendência local - Casos Particulares

1.  Nível local ou passeio aleatório + ruído; neste caso $\beta_t = 0$.

2.  Nível local com "drift"; neste caso $\sigma_{\xi}^2 = 0$.

3.  Tendência suave; neste caso $\sigma_{\eta}^2 = 0$.

4.  Tendência determinística; neste caso $\sigma_{\eta}^2 = \sigma_{\xi}^2 = 0$.

####Obs:

- A especificação da tendência é baseada em informações a priori da série e/ou no gráfico das observações.

- Na dúvida estima-se o modelo geral e testa-se a significância de cada componente no vetor de estados. Em particular, se $\sigma_{\xi}^2 = 0$, podemos testar se $\beta$, agora fixo, também é zero.



---
class: middle
##Modelo Estrutural Básico

- O modelo estrutural básico é definido por meio de:

\begin{align}
Z_t   =& \mu_t + \gamma_t + \epsilon_t \\
\mu_t =& \mu_{t-1} + \beta_{t-1} + \eta_t \\
\beta_t =& \beta_{t-1} + \xi_t. \\
\gamma_t =& - S_{t-1} - \ldots - S_{t-s+1} + \omega_t
\end{align}
assumindo que $t = 1, \ldots, n$ e que $s$ refere-se ao número de períodos 
sazonais, $\epsilon_t \sim N(0,\sigma^2_{\epsilon})$, 
$\eta_t \sim N(0,\sigma^2_{\eta})$, $\xi_t \sim N(0,\sigma^2_{\xi})$ e
$\omega_t \sim N(0,\sigma_{\omega}^2)$, 

- com $\epsilon_t$, $\omega_t$, $\eta_t$ e $\xi_t$ são ruídos brancos mutuamemte não 
correlacionados.


---
class: inverse, middle, center
##Representação em espaço de estados


---
class: middle
##Representação em espaço de estados

- Todo modelo linear de séries temporais $q$-dimensionais tem representação em espaço de estados.

- Essa representação relaciona o vetor de observações $\left\{ Z_t \right\}$ e o vetor de ruídos $\nu_t$, através de um processo de Markov $\left\{ X_t \right\}$, $p$ dimensional, denominado vetor de estados.

- O modelo de espaço de estados é constituídos por duas equações: a equação de observação e a equação de estados.


---
class: middle
##Representação em espaço de estados

- Matematicamente, o modelo de espaço de estados para uma série temporal univariada pode ser representado da seguinte maneira:

\begin{align}
Z_t   =& \mathbf{A}_t \mathbf{X}_t + \nu_t \phantom{111} \mbox{(equação de observação)}\\
\mathbf{X}_{t}  =& \mathbf{G}_t \mathbf{X}_{t-1}  + \mathbf{w}_t, \phantom{11} t = 1, \ldots, N.  \phantom{111} \mbox{(equação de estado)}
\end{align}

em que $\mathbf{A}$ é a matriz do sistema (matriz de variáveis explanatórias), de ordem $(q \times p)$;

- $\nu_t$ é o ruído de observação, de ordem $(q \times 1)$, não correlacionado, com média zero e variância $\mathbf{R}$;

- $\mathbf{G}$ é a matriz de transição (matriz de evolução), de ordem  $(p \times p)$ e 

- $\mathbf{w}_t$ é um vetor de ruídos não correlacionados, representando a perturbação do sistema, de ordem $(p \times 1)$, com média zero e matriz de covariâncias $\textbf{Q}$.

- Para séries univariadas tem-se $q=1$.

---
class: middle
##Representação em espaço de estados

- No modelo de espaço de estados assume-se que:

- O estado inicial $\mathbf{X}_0$ tem média $\boldsymbol{\mu}_0$ e matriz de covariâncias $\boldsymbol{\Sigma}_0$;

- os vetores de ruídos $\nu_t$ e $\mathbf{w}_t$ são não correlacionados entre si e não correlacionados com o estado inicial, isto é,

- $E[\nu_t\mathbf{w}_s^{'}] = 0, \phantom{11} \forall t, s = 1, \ldots, N.$
- $E[\nu_t\mathbf{X}_0^{'}] = 0 \phantom{11} \mbox{e} \phantom{11} E[\mathbf{w}_t\mathbf{X}_0^{'}] = 0, \phantom{11} \forall t, s = 1, \ldots, N.$

- Dizemos que o modelo de espaço de estados é gaussiano quando vetores de ruídos forem normalmente distribuídos. 

- O vetor $\mathbf{A}$ e a matriz $\mathbf{G}$ são não estocásticas; assim se houver variação no tempo estes serão pré-determinados. Quando forem constantes no tempo será dito *homogêneo no tempo*.

- O vetor de estados **não é diretamente observado**; o que se observa é uma versão linear dele, adicionada a um ruído. 



---
class: inverse, middle, center
##Inferência Sequencial

---
class: middle
##Inferência Sequencial (Hedibert Freitas Lopes)

- Um dos aspectos de um modelo dinâmico é que em qualquer tempo $t$, a inferência pode ser baseada na distribuição atualizada $\mathbf{X}_t|\mathbf{Z}_t$.

- Inferência sequencial executa isso ao longo do tempo:

- Existem 3 operações básicas:

- Evolução;

- Predição;

- Atualização.

---
class: middle
##Evolução (Hedibert Freitas Lopes)

- Evolução de $p(\mathbf{X}_{t-1}|\mathbf{Z}^{t-1})$ para $p(\mathbf{X}_t|\mathbf{Z}^{t-1})$.

- Considere no instante $t-1$, a distribuição atualizada de $\mathbf{X}_{t-1}$ condicionada a $\mathbf{Z}^{t-1}$ como sendo

$$\mathbf{X}_{t-1}|\mathbf{Z}^{t-1} \sim N(\mathbf{x}_{t-1}^{t-1}, \mathbf{P}^{t-1}_{t-1}).$$

em que $\mathbf{Z}^{t-1} = \left[Z_1, Z_2, \ldots, Z_{t-1}\right],$ $\mathbf{x}_{t-1}^{t-1} = E[\mathbf{X}_{t-1}|\mathbf{Z}^{t-1}]$ e
$\mathbf{P}^{t-1}_{t-1} = Var[\mathbf{X}_{t-1}|\mathbf{Z}^{t-1}].$

- Supondo que os ruídos e os estados sejam normalmente distribuídos, a partir da equação do sistema podemos determinar a distribuição $\mathbf{X}_t$ condicionado a $\mathbf{X}_{t-1}$, ou seja,

$$\mathbf{X}_t|\mathbf{X}_{t-1} \sim N(\mathbf{G}_t\mathbf{X}_{t-1}, \mathbf{Q}).$$

---
class: middle
##Evolução (Hedibert Freitas Lopes)

- Agora supondo propriedade Markoviana temos:

$$p(\mathbf{X}_{t-1}, \mathbf{X}_{t}|\mathbf{Z}^{t-1}) = p(\mathbf{X}_{t-1}|\mathbf{Z}^{t-1}) p(\mathbf{X}_t|\mathbf{X}_{t-1}).$$

Consequentemente, a distribuição de $\mathbf{X}_{t}$ condicionado a $\mathbf{Z}^{t-1}$ é dada por:


$$p(\mathbf{X}_t|\mathbf{Z}^{t-1}) = \int p(\mathbf{X}_{t-1}, \mathbf{X}_{t}|\mathbf{Z}^{t-1}) d \mathbf{X}_{t-1}$$
em que utilizando propriedades de [esperança condicional](https://en.wikipedia.org/wiki/Conditional_expectation#Basic_properties) e de [variância condicional](https://en.wikipedia.org/wiki/Law_of_total_variance) temos:

\begin{align}
E[\mathbf{X}_t|\mathbf{Z}^{t-1}] =& E[E[\mathbf{X}_t|\mathbf{X}_{t-1}]|\mathbf{Z}^{t-1}] \\
=& E[\mathbf{G}_t  \mathbf{X}_{t-1} | \mathbf{Z}^{t-1} ] = \mathbf{G}_t 
E[\mathbf{X}_{t-1} | \mathbf{Z}^{t-1} ] = \mathbf{G}_t \mathbf{x}_{t-1}^{t-1}.
\end{align}

\begin{align}
Var[\mathbf{X}_t|\mathbf{Z}^{t-1}] =& E[Var[\mathbf{X}_t|\mathbf{X}_{t-1}, \mathbf{Z}^{t-1}]|\mathbf{Z}^{t-1}] +
Var[E[\mathbf{X}_{t} | \mathbf{X}_{t-1},\mathbf{Z}^{t-1} ]|\mathbf{Z}^{t-1}]  \\
=& E[Var[\mathbf{X}_t|\mathbf{X}_{t-1}]|\mathbf{Z}^{t-1}] +
Var[E[\mathbf{X}_{t} | \mathbf{X}_{t-1} ]|\mathbf{Z}^{t-1}] \\
=& \mathbf{Q} + Var[\mathbf{G}_{t}  \mathbf{X}_{t-1} |\mathbf{Z}^{t-1}] \\
=&  \mathbf{Q} + \mathbf{G}_{t}\mathbf{P}_{t-1}^{t-1} \mathbf{G}_{t}^{'}.
\end{align}

Logo, $\mathbf{X}_t|\mathbf{Z}^{t-1} \sim N(\mathbf{G}_t \mathbf{x}_{t-1}^{t-1}, \mathbf{Q} + \mathbf{G}_{t}\mathbf{P}_{t-1}^{t-1} \mathbf{G}_{t}^{'} ).$

---
class: middle
##Predição (Hedibert Freitas Lopes)

- Uma predição a um passo a frente pode ser feita, notando que

\begin{align}
p(Z_t, \mathbf{X}_t|\mathbf{Z}^{t-1}) = p(\mathbf{X}_t|\mathbf{Z}^{t-1}) p(Z_t|\mathbf{X}_t) 
\end{align}
pois estamos assumindo que $Z_t|\mathbf{X}_t \perp \mathbf{Z}^{t-1}.$

- Assim, a distribuição de $Z_t, \mathbf{X}_t| \mathbf{Z}^{t-1}$ pode ser obtida levando a seguinte distribuição:

$$p(Z_t | \mathbf{Z}^{t-1}) = \int p(Z_t, \mathbf{X}_t| \mathbf{Z}^{t-1}) d\mathbf{X}_t$$

Ou seja, $\mathbf{Z}_t | \mathbf{Z}_{t-1} \sim N(\mathbf{A}_t\mathbf{x}_{t}^{t-1}, \mathbf{A}_t\mathbf{P}_t^{t-1}\mathbf{A}_t^{'}+\mathbf{R}),$ pois a partir da equação de observação


\begin{align}
E[Z_t|\mathbf{Z}^{t-1}] =& E[E[Z_t|\mathbf{X}_{t}]|\mathbf{Z}^{t-1}] \\
=& E[\mathbf{A}_t  \mathbf{X}_{t} | \mathbf{Z}^{t-1} ] = \mathbf{A}_t 
E[\mathbf{X}_{t} | \mathbf{Z}^{t-1} ] = \mathbf{A}_t \mathbf{x}_{t}^{t-1}.
\end{align}

\begin{align}
Var[Z_t|\mathbf{Z}^{t-1}] =& E[Var[Z_t|\mathbf{X}_{t}, \mathbf{Z}^{t-1}]|\mathbf{Z}^{t-1}] +
Var[E[Z_{t} | \mathbf{X}_{t},\mathbf{Z}^{t-1} ]|\mathbf{Z}^{t-1}]  \\
=& E[Var[Z_t|\mathbf{X}_{t}]|\mathbf{Z}^{t-1}] +
Var[E[Z_{t} | \mathbf{X}_{t} ]|\mathbf{Z}^{t-1}] \\
=& \mathbf{R} + Var[\mathbf{A}_{t}  \mathbf{X}_{t} |\mathbf{Z}^{t-1}] \\
=&  \mathbf{R} + \mathbf{A}_{t}\mathbf{P}_{t}^{t-1} \mathbf{A}_{t}^{'}.
\end{align}


---
class: middle
##Atualização  - Filtro de Kalman (Hedibert Freitas Lopes)

- A atualização é desenvolvida via Teorema de Bayes

$$p(\mathbf{X}_t|\mathbf{Z}^t) = p(\mathbf{X}_t|Z_t,\mathbf{Z}^{t-1}) = \frac{p(Z_t|\mathbf{X}_t,\mathbf{Z}^{t-1})p(\mathbf{X}_t|\mathbf{Z}^{t-1})}{p(Z_t|\mathbf{Z}^{t-1})} = \frac{p(Z_t|\mathbf{X}_t)p(\mathbf{X}_t|\mathbf{Z}^{t-1}) }{p(Z_t|\mathbf{Z}^{t-1})}.$$
- Portanto, a distribuição conjunta é dada por 
$$p(Z_t|\mathbf{X}_t,\mathbf{Z}^{t-1})p(\mathbf{X}_t|\mathbf{Z}^{t-1}) = p(\mathbf{X}_t, Z_t|\mathbf{Z}^{t-1}),$$

- Ou seja,

\begin{eqnarray}
\left[
\begin{array}{c}
\mathbf{X}_t | \mathbf{Z}_{t-1}\\
Z_{t} | \mathbf{Z}_{t-1}  
\end{array} \right]
\sim 
N \left(
  \left[
    \begin{array}{c}
    \mathbf{x}_t^{t-1} \\
    \mathbf{A} \mathbf{x}_t^{t-1}
    \end{array} \right], 
  \left[
    \begin{array}{cc}
    \mathbf{P}_t^{t-1} & \mathbf{P}_t^{t-1}\mathbf{A}^{'} \\
      \mathbf{A}\mathbf{P}_t^{t-1} & \mathbf{A}\mathbf{P}_t^{t-1}\mathbf{A}^{'} + \mathbf{R}
    \end{array} \right] \right).
\end{eqnarray}


- Aplicando [propriedades de normal multivariada](https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Conditional_distributions), temos: $\mathbf{X}_t|\mathbf{Z}^t \sim N(\mathbf{x}_{t}^{t},\mathbf{P}_{t}^{t}),$ em que

$$\mathbf{x}_{t}^{t} =  \mathbf{x}_{t}^{t-1} + \mathbf{P}_{t}^{t-1}\mathbf{A}^{'}(\mathbf{A}\mathbf{P}_{t}^{t-1}\mathbf{A}^{'} + \mathbf{R})^{-1}(Z_t - \mathbf{A}\mathbf{x}_{t}^{t-1})$$
e variância

\begin{align}
\mathbf{P}_{t}^{t} = \mathbf{P}_{t}^{t-1} - \mathbf{P}_{t}^{t-1}\mathbf{A}^{'}(\mathbf{A}\mathbf{P}_{t}^{t-1}\mathbf{A}^{'} + \mathbf{R})^{-1}\mathbf{A}\mathbf{P}_{t}^{t-1}) 
= \left[\mathbf{I} - \mathbf{P}_{t}^{t-1}\mathbf{A}^{'} (\mathbf{A}\mathbf{P}_{t}^{t-1}\mathbf{A}^{'} + \mathbf{R})^{-1}\mathbf{A}\right]\mathbf{P}_{t}^{t-1}.
\end{align}


---
class: middle
##Suavizador de Kalman - Algoritmo

- Para os modelos dinâmicos com condições iniciais $\mathbf{x}_N^N$ e $\mathbf{P}_N^N,$ temos para $t = N, N-1, \ldots, 1.$

\begin{align}
\mathbf{x}_{t-1}^N =& \mathbf{x}_{t-1}^{t-1} + \mathbf{J}_{t-1}(\mathbf{x}_{t}^N -\mathbf{x}_{t}^{t-1} ) \\
\mathbf{P}_{t-1}^N =& \mathbf{P}_{t-1}^{t-1} +  \mathbf{J}_{t-1}(\mathbf{P}_{t}^N - \mathbf{P}_{t}^{t-1})\mathbf{J}_{t-1}^{'}
\end{align}

em que $\mathbf{J}_{t-1} =  \mathbf{P}_{t-1}^{t-1}\mathbf{G}_t\left[\mathbf{P}_{t}^{t-1}\right]^{-1}.$

- Assim, o suavizador de Kalman fornece as estimativas do vetor de estados e da matriz de covariâncias no instante $t-1$, utilizando como informação todas as observações $Z_1, Z_2, \ldots, Z_N$ da série temporal. [explicações](https://communities.sas.com/t5/SAS-Communities-Library/Kalman-Filtering-and-Kalman-Smoothing-in-PROC-UCM/ta-p/338797#:~:text=Kalman%20filtering%20uses%20all%20the,and%20uses%20all%20the%20data.&text=The%20smoothing%20gives%20a%20good,matrix%20of%20the%20state%20variables.) [ou](https://christophertonetti.com/files/notes/Nakata_Tonetti_KalmanFilterAndSmoother.pdf.) 


---
class: middle
##Função de Verossimilhança

- A função de verossimilhança pode ser calculada através das quantidades obtidas pelo filtro de Kalman.

- Suponha $Z_t | \mathbf{Z}_{t-1} \sim N(\mathbf{A}\mathbf{x}_{t}^{t-1},\mathbf{A}\mathbf{P}_{t}^{t-1}\mathbf{A}^{'} + \mathbf{R})$ e considere agora $\epsilon_t = Z_t - E[Z_t|\mathbf{Z}_{t-1}]$. Dessa forma, temos:

\begin{align}
  E[\epsilon_t] =& E[Z_t - E[Z_t|\mathbf{Z}_{t-1}]] \\
  =& E[Z_t] - E[E[Z_t|\mathbf{Z}_{t-1}]] \\
  =& E[Z_t] - E[Z_t] \\
  =& 0.
\end{align}

\begin{align}
  Var[\epsilon_t] =& Var[Z_t - E[Z_t|\mathbf{Z}^{t-1}]] \\
  =& Var[Z_t - E[Z_t|\mathbf{Z}^{t-1}]] \\
  =& Var[\mathbf{A}\mathbf{X}_{t} + \nu_t - \mathbf{A}\mathbf{x}_{t}^{t-1}] \\
  =& Var[\mathbf{A}(\mathbf{X}_{t} - \mathbf{x}_{t}^{t-1})] + Var[\nu_t ] \\
  =& \mathbf{A}Var[(\mathbf{X}_{t} - \mathbf{x}_{t}^{t-1})]\mathbf{A}^{'} + \mathbf{R} 
\end{align}

---
class: middle
##Função de Verossimilhança

- Lembrando que 

\begin{align}
Var[(\mathbf{X}_{t} - \mathbf{x}_{t}^{t-1})] =& E[(\mathbf{X}_t - \mathbf{x}_{t}^{t-1})(\mathbf{X}_t - \mathbf{x}_{t}^{t-1})^{'} ] \\
=&  E[(\mathbf{X}_t - \mathbf{x}_{t}^{t-1})(\mathbf{X}_t - \mathbf{x}_{t}^{t-1})^{'}|\mathbf{Z}^{t-1} ] = \mathbf{P}_{t}^{t-1}
\end{align}

Logo,

\begin{align}
 \boldsymbol{\Sigma}_{\epsilon_t} = Var[\epsilon_t] = \mathbf{A}\mathbf{P}_{t}^{t-1}\mathbf{A}^{'} + \mathbf{R}. 
\end{align}


Assim, podemos definir o logaritmo da função de verossimilhança da seguinte forma

$$l(\Theta|\mathbf{Z}) = -\frac{1}{2}\sum_{t=1}^N\log|\boldsymbol{\Sigma}_{\epsilon_t}| - \frac{1}{2}\sum_{t=1}^N \boldsymbol{\epsilon}_t^{'}\boldsymbol{\Sigma}_{\epsilon_t}^{-1}\boldsymbol{\epsilon}_t,$$

- Nesse caso, o logaritmo da função de verossmilhança é não linear com relação aos parâmetros, então métodos numéricos devem ser adotados.


---
class: inverse, middle, center
##Exemplos Práticos no R


---
class: middle
##Exemplos 1 - Série $A_{10}$

- Como primeiro exemplo vamos analisar a Série $A_{10}$: Índice de Custo de Vida no Município de São Paulo; observações mensais de janeiro de 1970 a junho de 1980.

- O primeiro passo seria plotar a série para verificar qual modelo estrutural é o mais adequado.

---
class: middle
##Exemplos 1 - Série $A_{10}$


```{r, echo = FALSE, warning=FALSE, message=FALSE}

library(tidyverse)
library(ggpmisc)
library(knitr)
library(kableExtra)
library(lubridate)
library(zoo)
library(httr)
library(xlsx)
library(fpp2)
library(forecast)
library(dlm)
library(gridExtra)

#Lendo os dados
url1 = 'https://www.ime.usp.br/~pam/ICV.xls'
a = GET(url1, write_disk(tf <- tempfile(fileext = ".xls")))
dat =  as_tibble(read.xlsx(tf, sheetIndex = 1))

#Plotar dados
g1 = ggplot(dat, aes(x = Mes.ano, y = ICV)) + geom_path() + theme_bw()
g2 = ggplot(dat, aes(x = Mes.ano, y = log(ICV))) + geom_path() + theme_bw()

grid.arrange(g1, g2,  nrow=2)
```

---
class: middle
##Exemplos 1 - Série $A_{10}$

- Analisando os gráficos dos slides anteriores, decidiu-se utilizar o modelo estrutural de tendência local para os dados em escala logaritmica.

####Modelo Estrutural

\begin{align}
Z_t   =& \mu_t + \epsilon_t \\
\mu_t =& \mu_{t-1} + \beta_{t-1} + \eta_t \\
\beta_t =& \beta_{t-1} + \xi_t.
\end{align}

####Modelo Estrutural na Forma de Espaço de Estados

\begin{eqnarray}
Z_t =& 
\left[
\begin{array}{cc}
1 & 0
\end{array} \right]
\left[
\begin{array}{c}
\mu_t \\
\beta_t
\end{array} \right] + \epsilon_t \\
\left[
\begin{array}{c}
\mu_t \\
\beta_t
\end{array} \right] =&
\left[
\begin{array}{cc}
1 & 1 \\
0 & 1
\end{array} \right]
\left[
\begin{array}{c}
\mu_{t-1} \\
\beta_{t-1}
\end{array} \right] +
\left[
\begin{array}{c}
\eta_{t} \\
\xi_{t-1}
\end{array} \right]
\end{eqnarray}


```{r, echo = FALSE, warning=FALSE, message=FALSE}

dados = ts(log(dat$ICV), start=c(1970,1), frequency=12)

#Ajuste de um modelo com tendência local  
mod <- StructTS(dados, type = "trend")
if (mod$code != 0) stop("optimizer did not converge")

```


---
class: middle
##Código em R 

```{r, eval = FALSE, warning=FALSE, message=FALSE}

dados = ts(log(dat$ICV), start=c(1970,1), frequency=12)

#Ajuste de um modelo com tendência local  
mod <- StructTS(dados, type = "trend")
if (mod$code != 0) stop("optimizer did not converge")

cat("Transitional variance:", mod$coef["level"],
"\n", "Slope variance:", mod$coef["slope"],
"\n", "Observational variance:", mod$coef["epsilon"],
"\n")

```


---
class: middle

####Estimativas dos Parâmetros de Variâncias
```{r, echo = FALSE, warning=FALSE, message=FALSE}
cat("Transitional variance:", mod$coef["level"],
"\n", "Slope variance:", mod$coef["slope"],
"\n", "Observational variance:", mod$coef["epsilon"],
"\n")

```



###Valores preditos dos estados latentes (Filtro de Kalman)

```{r, echo = FALSE, warning=FALSE, message=FALSE}
data.frame(Obs=120:126,Pred= mod$fitted[120:126,])
```

####Código para Diagnostico do Modelo

```{r, eval = FALSE, warning=FALSE, message=FALSE}
tsdiag(mod)
```

---
class: middle

##Diagnostico do Modelo

```{r, echo = FALSE, warning=FALSE, message=FALSE}
tsdiag(mod)
```



---
class:  middle

##Suavização - Código em R

```{r, echo = FALSE, warning=FALSE, message=FALSE}
pred = tsSmooth(mod)
plot(pred)
```
                                         

---
class:  middle

##Suavização - Código em R

```{r, eval = FALSE, warning=FALSE, message=FALSE}
pred = tsSmooth(mod)
plot(pred)
```
  
##Previsão 12 meses na frente

```{r, eval = FALSE, warning=FALSE, message=FALSE}
KalmanForecast(mod$model,n.ahead=12)
```   

---
class:  middle

##Suavização - Código em R

```{r, echo = FALSE, warning=FALSE, message=FALSE}
pred = tsSmooth(mod)
plot(pred)
```

---
class:  middle


```{r, echo = FALSE, warning=FALSE, message=FALSE}
KalmanForecast(mod$model,n.ahead=12)
```    

---
class: middle

##Interpretação dos Resultados 


- Analises dos resultados sugerem que o ruído da observação seja nulo, pois, $\sigma^2_{\epsilon} = 0.$ (Conclusão tirada do livro do Morettin).

- Uma vez que a variância da inclinação também é um valor baixo, vamos testar o modelo de passeio aleatório.


---
class: middle
####Exemplos 1 - Passeio Aleatório

\begin{align}
Z_t   =& \mu_t \\
\mu_t =& \mu_{t-1} +  \eta_t.
\end{align}

####Modelo Estrutural na Forma de Espaço de Estados

Reconhecendo que $\mathbf{A}_t = 1, \mathbf{X_t} = \mu_t, \nu_t = 0, \mathbf{G}_t = 1, w_t = \eta_t$, tem-se o modelo de passeio aleatório representado como um modelo de espaço de estados.



---
class: middle
####Passeio Aleatório - Código no R

```{r,  warning=FALSE, message=FALSE}

mod2 = StructTS(dados, type = "level", fixed = c(NA,0))

cat("Transitional variance:", mod2$coef["level"],"\n")

```



---
class: middle

##Diagnostico do Modelo

```{r, echo = FALSE, warning=FALSE, message=FALSE}
tsdiag(mod2)
```

---
class: middle

####Interpretação dos Resultados 

 - Entre esses dois modelos ficamos com o primeiro, pois análise de diagnostico do passeio aleatório indica que o modelo está mal especificado.
 
 

